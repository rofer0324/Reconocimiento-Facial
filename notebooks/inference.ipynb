{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6799c35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1751315649.426786   13222 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torch.nn.functional import normalize\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Cargar backbone\n",
    "backbone = models.resnet50(pretrained=False)\n",
    "in_features = backbone.fc.in_features\n",
    "backbone.fc = nn.Identity()\n",
    "checkpoint = torch.load(\"../models/arcface_backbone.pth\")\n",
    "backbone.load_state_dict(checkpoint[\"backbone\"])\n",
    "\n",
    "embedding_layer = torch.nn.Linear(in_features, 512)\n",
    "embedding_layer.load_state_dict(checkpoint[\"embedding\"])\n",
    "\n",
    "backbone = backbone.to(DEVICE).eval()\n",
    "embedding_layer = embedding_layer.to(DEVICE).eval()\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((112,112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# Galería de embeddings\n",
    "reference_db = np.load(\"../models/gallery_embeddings.npy\", allow_pickle=True).item()\n",
    "\n",
    "# Mediapipe detection\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "face_detector = mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.9)\n",
    "\n",
    "def get_embedding(face_img):\n",
    "    face_tensor = transform(face_img).unsqueeze(0).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        features = backbone(face_tensor)\n",
    "        emb = embedding_layer(features)\n",
    "        emb = normalize(emb, dim=1)\n",
    "    return emb.squeeze(0).cpu().numpy()\n",
    "\n",
    "def recognize_face(embedding, threshold=0.91):\n",
    "    best_match = None\n",
    "    best_score = -1\n",
    "    for name, ref_emb in reference_db.items():\n",
    "        score = np.dot(embedding, ref_emb)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_match = name\n",
    "    if best_score >= threshold:\n",
    "        return best_match\n",
    "    return \"Desconocido\"\n",
    "\n",
    "# Cambiar aquí\n",
    "cap = cv2.VideoCapture(0)  # Webcam\n",
    "# cap = cv2.VideoCapture(\"../data/crudo/Abir1.mp4\")  # Video\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_detector.process(rgb)\n",
    "\n",
    "    if results.detections:\n",
    "        for det in results.detections:\n",
    "            bbox = det.location_data.relative_bounding_box\n",
    "            ih, iw, _ = frame.shape\n",
    "            x1 = max(int(bbox.xmin * iw), 0)\n",
    "            y1 = max(int(bbox.ymin * ih), 0)\n",
    "            w = int(bbox.width * iw)\n",
    "            h = int(bbox.height * ih)\n",
    "            x2 = min(x1 + w, iw)\n",
    "            y2 = min(y1 + h, ih)\n",
    "\n",
    "            face_img = frame[y1:y2, x1:x2]\n",
    "            if face_img.size == 0:\n",
    "                continue\n",
    "\n",
    "            # Reconocimiento\n",
    "            emb = get_embedding(face_img)\n",
    "            name = recognize_face(emb)\n",
    "\n",
    "            # Bounding box\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0,255,0), 2)\n",
    "            cv2.putText(frame, name, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "\n",
    "            # Dibujar keypoints\n",
    "            for kp in det.location_data.relative_keypoints:\n",
    "                kp_x = int(kp.x * iw)\n",
    "                kp_y = int(kp.y * ih)\n",
    "                cv2.circle(frame, (kp_x, kp_y), 2, (0, 250, 0), -1)\n",
    "\n",
    "    cv2.imshow(\"Recognition\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# === Procesar CSV al final ===\n",
    "csv_file = \"../results/asistencia.csv\"   # Cambia esta ruta si tu CSV está en otro lado\n",
    "\n",
    "# Verificar si el archivo existe\n",
    "if not os.path.exists(csv_file):\n",
    "    # Crear un DataFrame vacío con columnas esperadas\n",
    "    df_empty = pd.DataFrame(columns=[\"Nombre\", \"Fecha\"])\n",
    "    df_empty.to_csv(csv_file, index=False)\n",
    "    print(\"Archivo 'asistencia.csv' creado vacío.\")\n",
    "\n",
    "# Leer el archivo CSV\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Convertir columna de fecha a datetime\n",
    "df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Ordenar por Nombre y Fecha\n",
    "df = df.sort_values(by=['Nombre', 'Fecha'])\n",
    "\n",
    "# Crear DataFrame vacío para resultados\n",
    "df_processed = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "# Procesar cada persona\n",
    "for nombre in df['Nombre'].unique():\n",
    "    df_nombre = df[df['Nombre'] == nombre]\n",
    "    primera = df_nombre.iloc[0]\n",
    "    ultima = df_nombre.iloc[-1]\n",
    "\n",
    "    # Agregar la primera fecha\n",
    "    df_processed = pd.concat([df_processed, pd.DataFrame([primera])])\n",
    "\n",
    "    # Agregar la última si es diferente\n",
    "    if not primera.equals(ultima):\n",
    "        df_processed = pd.concat([df_processed, pd.DataFrame([ultima])])\n",
    "\n",
    "# Guardar el CSV con los resultados\n",
    "df_processed.to_csv(csv_file, index=False)\n",
    "\n",
    "print(\"Archivo CSV procesado: primeras y últimas fechas por persona.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entorno",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
