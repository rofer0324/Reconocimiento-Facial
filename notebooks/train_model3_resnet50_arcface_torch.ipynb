{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0596830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21060104",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcFace(nn.Module):\n",
    "    def __init__(self, in_features, out_features, s=30.0, m=0.50, easy_margin=False):\n",
    "        super(ArcFace, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt(1.0 - torch.clamp(cosine**2, 0, 1))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "\n",
    "        one_hot = torch.zeros_like(cosine)\n",
    "        one_hot.scatter_(1, label.view(-1,1), 1.0)\n",
    "\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9978284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetArcModel(nn.Module):\n",
    "    def __init__(self, num_classes, backbone=\"resnet50\", embedding_size=512):\n",
    "        super(ResNetArcModel, self).__init__()\n",
    "        resnet = getattr(models, backbone)(weights=True)\n",
    "        in_features = resnet.fc.in_features\n",
    "        resnet.fc = nn.Identity()\n",
    "\n",
    "        self.backbone = resnet\n",
    "        self.embedding = nn.Linear(in_features, embedding_size)\n",
    "        self.arcface = ArcFace(embedding_size, num_classes)\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        x = self.backbone(x)\n",
    "        x = self.embedding(x)\n",
    "        if labels is not None:\n",
    "            logits = self.arcface(x, labels)\n",
    "            return logits\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3726b5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases: ['Abir Ahmed', 'Adriana Sanchez', 'Adriana Solanilla', 'Alejandro Tulipano', 'Amy Olivares', 'Andrea Pipino', 'Blas de Leon', 'Carlos Beitia', 'Carlos Hernandez', 'Cesar Rodriguez', 'Javier Bustamante', 'Jeremy Sanchez', 'Jonathan Peralta', 'Kevin Rodriguez', 'Lucia Cardenas', 'Mahir Arcia', 'Michael Jordan']\n",
      "Número de clases: 17\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((112,112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    root=\"../data/preprocessed/train\",\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "num_classes = len(train_dataset.classes)\n",
    "print(\"Clases:\", train_dataset.classes)\n",
    "print(\"Número de clases:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bc14160",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNetArcModel(num_classes=num_classes, embedding_size=512).cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "228bf5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 78/78 [00:06<00:00, 12.80it/s, acc=0.998, loss=8.89e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 1 completed. Avg Loss: 0.0076, Acc: 0.9976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 78/78 [00:06<00:00, 12.79it/s, acc=1, loss=2.91e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 2 completed. Avg Loss: 0.0002, Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 78/78 [00:06<00:00, 12.70it/s, acc=1, loss=0.000881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 3 completed. Avg Loss: 0.0000, Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 78/78 [00:06<00:00, 12.63it/s, acc=1, loss=4.97e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 4 completed. Avg Loss: 0.0001, Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 78/78 [00:06<00:00, 12.57it/s, acc=1, loss=1.3e-5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 5 completed. Avg Loss: 0.0000, Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 78/78 [00:06<00:00, 12.53it/s, acc=1, loss=2.44e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 6 completed. Avg Loss: 0.0003, Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 78/78 [00:06<00:00, 12.68it/s, acc=1, loss=1.19]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 7 completed. Avg Loss: 0.0153, Acc: 0.9996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 78/78 [00:06<00:00, 12.90it/s, acc=0.995, loss=0.000508]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 8 completed. Avg Loss: 0.0617, Acc: 0.9948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 78/78 [00:06<00:00, 12.20it/s, acc=0.98, loss=0.0035]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 9 completed. Avg Loss: 0.2171, Acc: 0.9803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 78/78 [00:06<00:00, 12.17it/s, acc=0.973, loss=0.0899]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 10 completed. Avg Loss: 0.2434, Acc: 0.9735\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    for images, labels in pbar:\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        logits = model(images, labels)  # solo si usas ArcFace\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        correct += (torch.argmax(logits, dim=1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        acc = correct / total\n",
    "        pbar.set_postfix(loss=loss.item(), acc=acc)\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = correct / total\n",
    "    print(f\"✅ Epoch {epoch+1} completed. Avg Loss: {avg_loss:.4f}, Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "# Guardar modelo completo\n",
    "torch.save(model.state_dict(), \"../models/arcface17.pth\")\n",
    "\n",
    "# Guardar solo backbone y embedding\n",
    "torch.save(\n",
    "    {\n",
    "        \"backbone\": model.backbone.state_dict(),\n",
    "        \"embedding\": model.embedding.state_dict()\n",
    "    },\n",
    "    \"../models/arcface_backbone17.pth\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7325b1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando Abir Ahmed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:00<00:00, 177.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando Adriana Sanchez...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 142.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando Adriana Solanilla...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 151.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando Alejandro Tulipano...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:00<00:00, 175.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando Amy Olivares...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 256.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando Andrea Pipino...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 186.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando Blas de Leon...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:00<00:00, 138.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando Carlos Beitia...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:00<00:00, 146.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando Carlos Hernandez...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:00<00:00, 144.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando Cesar Rodriguez...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:00<00:00, 139.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando Javier Bustamante...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 105.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando Jeremy Sanchez...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 143.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando Jonathan Peralta...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 148.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando Kevin Rodriguez...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:00<00:00, 139.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando Lucia Cardenas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:00<00:00, 142.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando Mahir Arcia...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 142.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando Michael Jordan...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 147.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Galería guardada en ../models/gallery_embeddings17.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DATASET_DIR = \"../data/preprocessed/test\"\n",
    "\n",
    "# Cargar backbone\n",
    "backbone = models.resnet50(weights=None)\n",
    "in_features = backbone.fc.in_features\n",
    "backbone.fc = nn.Identity()\n",
    "checkpoint = torch.load(\"../models/arcface_backbone17.pth\")\n",
    "backbone.load_state_dict(checkpoint[\"backbone\"])\n",
    "\n",
    "embedding_layer = torch.nn.Linear(in_features, 512)\n",
    "embedding_layer.load_state_dict(checkpoint[\"embedding\"])\n",
    "\n",
    "backbone = backbone.to(DEVICE).eval()\n",
    "embedding_layer = embedding_layer.to(DEVICE).eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((112,112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "class_embeddings = {}\n",
    "\n",
    "for class_name in os.listdir(DATASET_DIR):\n",
    "    class_dir = os.path.join(DATASET_DIR, class_name)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "\n",
    "    embeddings = []\n",
    "    image_files = [f for f in os.listdir(class_dir) if f.lower().endswith((\".jpg\", \".png\"))]\n",
    "\n",
    "    print(f\"Procesando {class_name}...\")\n",
    "\n",
    "    for img_file in tqdm(image_files):\n",
    "        img_path = os.path.join(class_dir, img_file)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        x = transform(img).unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            features = backbone(x)\n",
    "            emb = embedding_layer(features)\n",
    "            emb = F.normalize(emb, dim=1)\n",
    "        embeddings.append(emb.squeeze(0).cpu())\n",
    "\n",
    "    mean_emb = torch.stack(embeddings).mean(0)\n",
    "    mean_emb = F.normalize(mean_emb, dim=0)\n",
    "    class_embeddings[class_name] = mean_emb.numpy()\n",
    "\n",
    "np.save(\"../models/gallery_embeddings17.npy\", class_embeddings)\n",
    "print(\"✅ Galería guardada en ../models/gallery_embeddings17.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c565d022",
   "metadata": {},
   "source": [
    "## Generar TSV\n",
    "* A partir del gallery_embeddings.npy\n",
    "\n",
    "Esto con el proposito de poder utilizar la pagina: https://projector.tensorflow.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "517ea4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivos embeddings.tsv y metadata.tsv generados.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "reference_db = np.load(\"../models/gallery_embeddings17.npy\", allow_pickle=True).item()\n",
    "\n",
    "# Ordenar por nombre\n",
    "items = sorted(reference_db.items())\n",
    "\n",
    "# Embeddings y etiquetas\n",
    "embeddings = [v for k,v in items]\n",
    "labels = [k for k,v in items]\n",
    "\n",
    "# Convertir a array\n",
    "embeddings = np.stack(embeddings)\n",
    "\n",
    "# Guardar embeddings.tsv\n",
    "np.savetxt(\"../models/embeddings.tsv\", embeddings, delimiter=\"\\t\", fmt=\"%.6f\")\n",
    "\n",
    "# Guardar metadata.tsv\n",
    "with open(\"../models/metadata.tsv\", \"w\") as f:\n",
    "    f.write(\"Label\\n\")\n",
    "    for label in labels:\n",
    "        f.write(f\"{label}\\n\")\n",
    "\n",
    "print(\"✅ Archivos embeddings.tsv y metadata.tsv generados.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
